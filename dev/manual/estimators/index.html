<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Estimators · Microstructure.jl</title><meta name="title" content="Estimators · Microstructure.jl"/><meta property="og:title" content="Estimators · Microstructure.jl"/><meta property="twitter:title" content="Estimators · Microstructure.jl"/><meta name="description" content="Documentation for Microstructure.jl."/><meta property="og:description" content="Documentation for Microstructure.jl."/><meta property="twitter:description" content="Documentation for Microstructure.jl."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img class="docs-light-only" src="../../assets/logo.png" alt="Microstructure.jl logo"/><img class="docs-dark-only" src="../../assets/logo-dark.png" alt="Microstructure.jl logo"/></a><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><a class="tocitem" href="../../getting_started/">Getting started</a></li><li><span class="tocitem">Manual</span><ul><li><a class="tocitem" href="../dMRI/">I/O functions</a></li><li><a class="tocitem" href="../compartments/">Tissue Compartments</a></li><li><a class="tocitem" href="../models/">Microstructure Models</a></li><li class="is-active"><a class="tocitem" href>Estimators</a><ul class="internal"><li><a class="tocitem" href="#MCMC"><span>MCMC</span></a></li><li><a class="tocitem" href="#Neural-Networks"><span>Neural Networks</span></a></li></ul></li><li><a class="tocitem" href="../multithreads/">Multi threads</a></li></ul></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../../tutorials/1_build_models/">How to build a microstructure model</a></li><li><a class="tocitem" href="../../tutorials/2_quality_of_fit/">How to check quality of fitting and mcmc samples</a></li><li><a class="tocitem" href="../../tutorials/3_data_generation/">How to generate training datasets</a></li><li><a class="tocitem" href="../../tutorials/4_noise_propagation/">How to evaluate accuracy and precision</a></li><li><a class="tocitem" href="../../tutorials/5_model_selection/">Which model to use</a></li></ul></li><li><a class="tocitem" href="../../guide/">Developer guide</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Manual</a></li><li class="is-active"><a href>Estimators</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Estimators</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/Tinggong/Microstructure.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/Tinggong/Microstructure.jl/blob/main/docs/src/manual/estimators.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Estimators"><a class="docs-heading-anchor" href="#Estimators">Estimators</a><a id="Estimators-1"></a><a class="docs-heading-anchor-permalink" href="#Estimators" title="Permalink"></a></h1><p>This page introduces two types of estimators in Microstructure.jl for estimating parameters and quantifying uncertainties: the Markov Chain Monte Carlo (MCMC) sampling method and Monte Carlo dropout using neural networks. These two types of estimators are flexibly parametrized, allowing you to specify sampling options for MCMC and training options for neural networks. </p><h2 id="MCMC"><a class="docs-heading-anchor" href="#MCMC">MCMC</a><a id="MCMC-1"></a><a class="docs-heading-anchor-permalink" href="#MCMC" title="Permalink"></a></h2><p>MCMC methods aim to generate independent samples from the posterior distributions of tissue parameters given certain MRI measurements. You will need to tune the sampler parameters for a specific biophysical model.</p><h3 id="Define-a-sampler-for-your-model"><a class="docs-heading-anchor" href="#Define-a-sampler-for-your-model">Define a sampler for your model</a><a id="Define-a-sampler-for-your-model-1"></a><a class="docs-heading-anchor-permalink" href="#Define-a-sampler-for-your-model" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Microstructure.Sampler" href="#Microstructure.Sampler"><code>Microstructure.Sampler</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Sampler(
    params::Tuple{Vararg{String}},
    prior_range::Tuple{Vararg{Tuple{Float64, Float64}}}, 
    proposal::Tuple{Vararg{&lt;:Any}},
    paralinks::Tuple{Vararg{Pair{String}}}, 
    nsamples::Int64 
    burnin::Int64
    thinning::Int64 
)</code></pre><p>Return a Sampler Type object for a biophysical model.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt;Sampler(
    params = (&quot;axon.da&quot;,&quot;axon.dpara&quot;,&quot;extra.dperp_frac&quot;,&quot;fracs&quot;),
    prior_range = ((1.0e-7,1.0e-5),(0.01e-9,0.9e-9),(0.0, 1.0),(0.0,1.0)),
    proposal = (Normal(0,0.25e-6), Normal(0,0.025e-9), Normal(0,0.05), MvNormal([0.0025 0 0;0 0.0001 0; 0 0 0.0001])),
    paralinks = (&quot;axon.d0&quot; =&gt; &quot;axon.dpara&quot;, &quot;extra.dpara&quot; =&gt; &quot;axon.dpara&quot;),
    nsamples = 70000,
    burnin = 20000
)
Sampler((&quot;axon.da&quot;, &quot;axon.dpara&quot;, &quot;extra.dperp_frac&quot;, &quot;fracs&quot;), ((1.0e-7, 1.0e-5), (1.0e-11, 9.0e-10), (0.0, 1.0), (0.0, 1.0)), (Normal{Float64}(μ=0.0, σ=2.5e-7), Normal{Float64}(μ=0.0, σ=2.5e-11), Normal{Float64}(μ=0.0, σ=0.05), ZeroMeanFullNormal(
dim: 3
μ: Zeros(3)
Σ: [0.0025 0.0 0.0; 0.0 0.0001 0.0; 0.0 0.0 0.0001]
)
), (&quot;axon.d0&quot; =&gt; &quot;axon.dpara&quot;, &quot;extra.dpara&quot; =&gt; &quot;axon.dpara&quot;), 70000, 20000, 1)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Tinggong/Microstructure.jl/blob/4cd70de05f7f038361ece2a66570d4a68f18ff93/src/estimators_mcmc.jl#L73-L103">source</a></section></article><h3 id="Define-a-noise-model"><a class="docs-heading-anchor" href="#Define-a-noise-model">Define a noise model</a><a id="Define-a-noise-model-1"></a><a class="docs-heading-anchor-permalink" href="#Define-a-noise-model" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Microstructure.Noisemodel" href="#Microstructure.Noisemodel"><code>Microstructure.Noisemodel</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Noisemodel(logpdf::Function, 
sigma_start::Float64, 
sigma_range::Tuple{Float64,Float64}, 
proposal::Distribution)</code></pre><p>Return a Noisemodel object with <code>logpdf</code> Function to calculate log likelihood of measurements (set this between <code>logp_gauss</code> and <code>logp_rician</code>),  <code>sigma_start</code> as the starting value of noise level, <code>sigma_range</code> as prior range and <code>proposal</code> distribution for MCMC sampling.</p><p><strong>Examples</strong></p><pre><code class="language-julia-repl hljs">julia&gt; Noisemodel()
Noisemodel(Microstructure.logp_gauss, 0.01, (0.005, 0.1), Distributions.Normal{Float64}(μ=0.0, σ=0.005))</code></pre><pre><code class="language-julia-repl hljs">julia&gt; Noisemodel(logpdf = logp_rician, sigma_start = 0.02, proposal = Normal(0,0.001))
Noisemodel(Microstructure.logp_rician, 0.02, (0.005, 0.1), Normal{Float64}(μ=0.0, σ=0.001))</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Tinggong/Microstructure.jl/blob/4cd70de05f7f038361ece2a66570d4a68f18ff93/src/estimators_mcmc.jl#L18-L37">source</a></section></article><h3 id="Run-MCMC-on-your-model-and-data"><a class="docs-heading-anchor" href="#Run-MCMC-on-your-model-and-data">Run MCMC on your model and data</a><a id="Run-MCMC-on-your-model-and-data-1"></a><a class="docs-heading-anchor-permalink" href="#Run-MCMC-on-your-model-and-data" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Microstructure.mcmc!" href="#Microstructure.mcmc!"><code>Microstructure.mcmc!</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><p>Method 1 generates pertubations within function, creates and returns a dict chain, and modify final model estimates in place. This method is useful in checking a few voxels, e.g. for quality of fitting, chain dignostics and optimizing sampler for models. </p><pre><code class="nohighlight hljs">mcmc!(
    estimates::BiophysicalModel,
    meas::Vector{Float64},
    protocol::Protocol,
    sampler::Sampler,
    noise::Noisemodel = Noisemodel(),
    rng::Int64 = 1
)</code></pre><pre><code class="language-julia-repl hljs">julia&gt; chain = mcmc!(estimates, measurements, protocol, sampler, noise_model, rng)</code></pre><p>Method 2 takes <code>chain</code> and <code>pertubations</code> as input, mutating <code>chain</code> in place which can be used to calculate finial estimates and uncertainties.  This method is used for processing larger dataset, e.g. for whole-barin/slices.  This method is used together with multi-threads processing that pre-allocate spaces for caching chains, avoiding creating them for each voxel.  This method also reuses <code>pertubations</code> for faster computation speed; we usually use very large numbers of pertubations (e.g. ~10^4) to densely sample the proposal distributions. </p><pre><code class="nohighlight hljs">mcmc!(
    chain::Vector{Any},
    estimates::BiophysicalModel,
    meas::Vector{Float64},
    protocol::Protocol,
    sampler::Sampler,
    pertubations::Vector{Vector{Any}},
    noise::Noisemodel = Noisemodel()
)</code></pre><pre><code class="language-julia-repl hljs">julia&gt; mcmc!(chain, estimates, meas, protocol, sampler, pertubations, noise_model))</code></pre><p><strong>References</strong></p><p>For using MCMC in microsturcture imaging, here are some recommended references:</p><p>Behrens, T.E.J., Woolrich, M.W., Jenkinson, M., Johansen-Berg, H., Nunes, R.G., Clare, S., Matthews, P.M., Brady, J.M., Smith, S.M., 2003. Characterization and Propagation of Uncertainty in Diffusion-Weighted MR Imaging. Magn Reson Med 50, 1077–1088. https://doi.org/10.1002/MRM.10609</p><p>Alexander, D.C., 2008. A General Framework for Experiment Design in Diffusion MRI and Its Application in Measuring Direct Tissue-Microstructure Features. Magn Reson Med 60, 439–448. https://doi.org/10.1002/mrm.21646</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Tinggong/Microstructure.jl/blob/4cd70de05f7f038361ece2a66570d4a68f18ff93/src/estimators_mcmc.jl#L291-L333">source</a></section></article><p>Function mcmc! runs on single thread and suitable for testing sampler parameters and inspecting chains for small dataset. After optimizing sampler parameters, if you are processing datasets with many voxels, use the threading function for multi-threads processing. Refer to multi-threads page for more details.</p><h2 id="Neural-Networks"><a class="docs-heading-anchor" href="#Neural-Networks">Neural Networks</a><a id="Neural-Networks-1"></a><a class="docs-heading-anchor-permalink" href="#Neural-Networks" title="Permalink"></a></h2><p>This module currently includes simple multi-layer perceptrons and training data generation function, which allows supervised training of the MLPs on synthesised data with given training parameter distributions. </p><h3 id="Specify-a-network-model-for-your-task"><a class="docs-heading-anchor" href="#Specify-a-network-model-for-your-task">Specify a network model for your task</a><a id="Specify-a-network-model-for-your-task-1"></a><a class="docs-heading-anchor-permalink" href="#Specify-a-network-model-for-your-task" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Microstructure.NetworkArg" href="#Microstructure.NetworkArg"><code>Microstructure.NetworkArg</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">NetworkArg(
    model::BiophysicalModel
    protocol::Protocol
    params::Tuple{Vararg{String}}
    prior_range::Tuple{Vararg{Tuple{Float64,Float64}}} # range for priors 
    prior_dist::Tuple{Vararg{&lt;:Any}}
    paralinks::Tuple{Vararg{Pair{String,&lt;:String}}} = ()
    noise_type::String = &quot;Gaussian&quot; # &quot;Rician&quot;    
    sigma_range::Tuple{Float64, Float64}
    sigma_dist::Distribution
    nsamples::Int64
    nin::Int64
    nout::Int64
    hidden_layers::Tuple{Vararg{Int64}}
    dropoutp::Union{&lt;:AbstractFloat, Tuple{Vararg{&lt;:AbstractFloat}}}
    actf::Function
)</code></pre><p>Return a <code>NetworkArg</code> object with necessary parameters to construct a neural network model  and generate training samples for specifc biophysical model. A test network architecture and training samples can be automaticlly determined from the modelling task by using function</p><pre><code class="nohighlight hljs">NetworkArg(model, protocol, params, prior_range, prior_dist, paralinks, noisetype, sigma_range, sigma_dist)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Tinggong/Microstructure.jl/blob/4cd70de05f7f038361ece2a66570d4a68f18ff93/src/estimators_nn.jl#L19-L42">source</a></section></article><h3 id="Specify-training-parameters"><a class="docs-heading-anchor" href="#Specify-training-parameters">Specify training parameters</a><a id="Specify-training-parameters-1"></a><a class="docs-heading-anchor-permalink" href="#Specify-training-parameters" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Microstructure.TrainingArg" href="#Microstructure.TrainingArg"><code>Microstructure.TrainingArg</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">TrainingArg(
    batchsize::Int64 
    lossf::Function
    lr::Float64
    epoch::Int64
    tv_split::Float64
    patience::Tuple{Int64,Int64} 
    device::Function
)</code></pre><p>Return <code>TrainingArg</code> Type object with fields related to how network will be trained. batch size; loss function; learning rate; number of epoches; validation/training data split; patience for train loss plateau, patience for validation loss to increase.  Patiences are currently not applied when training and validating on generated training samples from uniform parameter distributions,  therefore training will stop when reaching the number of epoches.  The patience parameter will be considered in the future when training with real data or generated data with other distributions. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Tinggong/Microstructure.jl/blob/4cd70de05f7f038361ece2a66570d4a68f18ff93/src/estimators_nn.jl#L61-L78">source</a></section></article><h3 id="Prepare-network-and-data-for-training"><a class="docs-heading-anchor" href="#Prepare-network-and-data-for-training">Prepare network and data for training</a><a id="Prepare-network-and-data-for-training-1"></a><a class="docs-heading-anchor-permalink" href="#Prepare-network-and-data-for-training" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Microstructure.prepare_training" href="#Microstructure.prepare_training"><code>Microstructure.prepare_training</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">prepare_training(arg::NetworkArg)</code></pre><p>Return (<code>mlp</code>, <code>inputs</code>, <code>labels</code>, <code>gt</code>); <code>mlp</code> is the multi-layer perceptron network model for the biophysical model;  <code>inputs</code> and <code>labels</code> are arrays of signals and scaled tissue parameters used for supervised training; and <code>gt</code> is a dict containing the ground truth tissue parameters without applying scaling. Scaling is applied in the training labels to ensure different tissue parameters are roughly in the same range as they are optimized together. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Tinggong/Microstructure.jl/blob/4cd70de05f7f038361ece2a66570d4a68f18ff93/src/estimators_nn.jl#L151-L158">source</a></section></article><p>&quot;prepare_training&quot; calls two functions to generate task specific MLP and training samples:</p><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Microstructure.create_mlp" href="#Microstructure.create_mlp"><code>Microstructure.create_mlp</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">create_mlp(
    ninput::Int, 
    noutput::Int, 
    hiddenlayers::Tuple{Vararg{Int}}, 
    dropoutp::Union{&lt;:AbstractFloat,Tuple{Vararg{&lt;:AbstractFloat}}}
    )</code></pre><p>Return a <code>mlp</code> with <code>ninput</code>/<code>noutput</code> as the number of input/output channels, and number of units in each layer specified in <code>hiddenlayers</code>;  &#39;dropoutp&#39; contains the dropout probalibities for dropout layers; it can be a single value (one dropout layer before output) or same length as the hidden layers </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Tinggong/Microstructure.jl/blob/4cd70de05f7f038361ece2a66570d4a68f18ff93/src/estimators_nn.jl#L179-L189">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Microstructure.generate_samples" href="#Microstructure.generate_samples"><code>Microstructure.generate_samples</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">generate_samples(
    model::BiophysicalModel,
    protocol::Protocol,
    params::Tuple{Vararg{String}},
    prior_range::Tuple{Vararg{Tuple{Float64,Float64}}}, 
    prior_dist::Tuple{Vararg{&lt;:Any}},
    nsample::Int,
    paralinks::Union{Pair{String},Tuple{Vararg{Pair{String}}}},
    sigma_range::Tuple{Float64, Float64},
    sigma::Distribution,
    noise_type::String=&quot;Gaussian&quot;,
    rng_seed,
)</code></pre><p>Generate and return training samples for a model using given priors of tissue parameters  and specified noise model (<code>&quot;Gaussian&quot;</code> or <code>&quot;Rician&quot;</code>) and noise level.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Tinggong/Microstructure.jl/blob/4cd70de05f7f038361ece2a66570d4a68f18ff93/src/estimators_nn.jl#L217-L233">source</a></section></article><h3 id="Training-on-generated-training-samples"><a class="docs-heading-anchor" href="#Training-on-generated-training-samples">Training on generated training samples</a><a id="Training-on-generated-training-samples-1"></a><a class="docs-heading-anchor-permalink" href="#Training-on-generated-training-samples" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Microstructure.train_loop!" href="#Microstructure.train_loop!"><code>Microstructure.train_loop!</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">train_loop!(
    mlp::Chain, 
    arg::TrainingArg, 
    inputs::Array{Float64,2}, 
    labels::Array{Float64,2}
)</code></pre><p>Train and update the <code>mlp</code> and return a Dict of training logs with train loss, training data loss and validation data loss for each epoch. This function works on cpu, which is sufficiently fast for most cases.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Tinggong/Microstructure.jl/blob/4cd70de05f7f038361ece2a66570d4a68f18ff93/src/estimators_nn.jl#L326-L335">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Microstructure.training" href="#Microstructure.training"><code>Microstructure.training</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">training(
    arg::TrainingArg, 
    net::NetworkArg, 
    rng_seed::Int
)</code></pre><p>Train and return the <code>mlp</code>, a Dict of training logs with train loss, training data loss and validation data loss for each epoch, and the training data the mlp was trained on. This function is for both cpu and gpu training</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Tinggong/Microstructure.jl/blob/4cd70de05f7f038361ece2a66570d4a68f18ff93/src/estimators_nn.jl#L388-L396">source</a></section></article><h3 id="Test-on-you-data"><a class="docs-heading-anchor" href="#Test-on-you-data">Test on you data</a><a id="Test-on-you-data-1"></a><a class="docs-heading-anchor-permalink" href="#Test-on-you-data" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Microstructure.test" href="#Microstructure.test"><code>Microstructure.test</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">test(mlp::Chain, data::Array{&lt;:AbstractFloat,2}, ntest)</code></pre><p>Return probabilistic estimates by applying a trained <code>mlp</code> to test data for <code>ntest</code> times with dropout layers on.</p><pre><code class="nohighlight hljs">test(mlp::Chain, data::Array{&lt;:AbstractFloat,2})</code></pre><p>Get deterministic estimates with dropout layers off</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/Tinggong/Microstructure.jl/blob/4cd70de05f7f038361ece2a66570d4a68f18ff93/src/estimators_nn.jl#L452-L461">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../models/">« Microstructure Models</a><a class="docs-footer-nextpage" href="../multithreads/">Multi threads »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.8.0 on <span class="colophon-date" title="Wednesday 5 February 2025 21:07">Wednesday 5 February 2025</span>. Using Julia version 1.10.8.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
